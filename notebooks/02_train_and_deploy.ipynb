{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e21b0924",
   "metadata": {},
   "source": [
    "# Acoustic Shield - Training & Deployment\n",
    "\n",
    "This notebook trains and deploys the audio classification model using AWS SageMaker.\n",
    "\n",
    "## Pipeline Overview\n",
    "1. **Setup Configuration** - Define S3 paths, IAM role, and hyperparameters\n",
    "2. **Create Training Job** - Fine-tune wav2vec2-base on audio data\n",
    "3. **Deploy Endpoint** - Deploy real-time inference endpoint\n",
    "4. **Test Endpoint** - Smoke test with sample audio\n",
    "\n",
    "## Dataset Structure\n",
    "Training data must be organized in audiofolder format:\n",
    "```\n",
    "s3://acousticshield-ml/train/\n",
    "‚îú‚îÄ‚îÄ Normal/*.wav\n",
    "‚îú‚îÄ‚îÄ TireSkid/*.wav\n",
    "‚îú‚îÄ‚îÄ EmergencyBraking/*.wav\n",
    "‚îî‚îÄ‚îÄ CollisionImminent/*.wav\n",
    "```\n",
    "\n",
    "## Audio Requirements\n",
    "- **Format**: WAV (mono or stereo)\n",
    "- **Sample Rate**: 16 kHz (auto-resampled if different)\n",
    "- **Duration**: 1-5 seconds recommended\n",
    "\n",
    "## Customization Options\n",
    "- **Change epochs**: Modify `EPOCHS` parameter (default: 4)\n",
    "- **Change learning rate**: Modify `LEARNING_RATE` (default: 3e-5)\n",
    "- **Change batch size**: Modify `BATCH_SIZE` (default: 8)\n",
    "- **Skip validation**: Set `VAL_S3 = None`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e508f5",
   "metadata": {},
   "source": [
    "## Step 1: Configuration\n",
    "\n",
    "‚ö†Ô∏è **IMPORTANT**: No region hardcoding - SageMaker auto-detects region from bucket location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903894c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.serializers import DataSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"‚úì Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85143d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Modify these parameters as needed\n",
    "# ============================================================================\n",
    "\n",
    "# S3 paths\n",
    "TRAIN_S3 = \"s3://acousticshield-ml/train_split/\"     # Training data (80% split)\n",
    "VAL_S3 = \"s3://acousticshield-ml/val/\"               # Validation data (20% split)\n",
    "MODEL_OUTPUT_S3 = \"s3://acousticshield-ml/models/\"   # Model artifacts output\n",
    "\n",
    "# IAM Role\n",
    "ROLE_NAME = \"role-sagemaker-train\"                    # IAM role name (not ARN)\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 1                 # Just 1 epoch for hackathon speed! (was 4)\n",
    "LEARNING_RATE = 5e-5       # Faster convergence (was 3e-5)\n",
    "BATCH_SIZE = 16            # Larger batches = faster (was 8)\n",
    "WARMUP_STEPS = 50          # Less warmup = faster (was 500)\n",
    "GRADIENT_ACCUMULATION = 1  # Gradient accumulation steps (increase for effective larger batch)\n",
    "\n",
    "# Instance configuration - Try these in order if you hit quota limits:\n",
    "# ‚ö†Ô∏è G5 instances often have 0 quota on new accounts - try G4DN first!\n",
    "# RECOMMENDED ORDER (try from top to bottom):\n",
    "#   \"ml.g4dn.xlarge\"    - NVIDIA T4 GPU, 16GB memory, ~$0.74/hour (MOST LIKELY to work!)\n",
    "#   \"ml.g4dn.2xlarge\"   - NVIDIA T4 GPU, 32GB memory, ~$1.00/hour (more memory)\n",
    "#   \"ml.g4dn.4xlarge\"   - NVIDIA T4 GPU, 64GB memory, ~$1.50/hour (even more memory)\n",
    "# IF G4DN FAILS, try older generations:\n",
    "#   \"ml.p2.xlarge\"      - NVIDIA K80 GPU, 61GB memory, ~$1.26/hour (older but usually available)\n",
    "#   \"ml.p3.2xlarge\"     - NVIDIA V100 GPU, 61GB memory, ~$3.83/hour (expensive, may have quota)\n",
    "# AVOID (usually 0 quota on new accounts):\n",
    "#   \"ml.g5.xlarge\"      - Quota = 0 on most new accounts ‚ùå\n",
    "#   \"ml.g5.2xlarge\"     - Quota = 0 on most new accounts ‚ùå\n",
    "TRAIN_INSTANCE_TYPE = \"ml.g4dn.xlarge\"  # Change this if you get quota errors\n",
    "TRAIN_INSTANCE_COUNT = 1                 # Number of training instances\n",
    "ENDPOINT_INSTANCE_TYPE = \"ml.m5.xlarge\" # CPU instance for inference\n",
    "ENDPOINT_INSTANCE_COUNT = 1              # Number of endpoint instances\n",
    "\n",
    "# Model configuration\n",
    "TRANSFORMERS_VERSION = \"4.28\"  # HuggingFace Transformers version (supports CPU)\n",
    "PYTORCH_VERSION = \"2.0\"        # PyTorch version\n",
    "PYTHON_VERSION = \"py310\"       # Python version\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Acoustic Shield - Training Configuration\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Training data: {TRAIN_S3}\")\n",
    "print(f\"Validation data: {VAL_S3 if VAL_S3 else 'None (will split from train)'}\")\n",
    "print(f\"Model output: {MODEL_OUTPUT_S3}\")\n",
    "print(f\"IAM Role: {ROLE_NAME}\")\n",
    "print(f\"\\nHyperparameters:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Warmup Steps: {WARMUP_STEPS}\")\n",
    "print(f\"\\nInstances:\")\n",
    "print(f\"  Training: {TRAIN_INSTANCE_TYPE} x {TRAIN_INSTANCE_COUNT}\")\n",
    "print(f\"  Endpoint: {ENDPOINT_INSTANCE_TYPE} x {ENDPOINT_INSTANCE_COUNT}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e55eea8",
   "metadata": {},
   "source": [
    "## Step 2: Initialize SageMaker Session\n",
    "\n",
    "Auto-detect region from S3 bucket location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233c3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect region from S3 bucket\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = TRAIN_S3.split('/')[2]  # Extract bucket from s3://bucket/path\n",
    "bucket_location = s3.get_bucket_location(Bucket=bucket_name)['LocationConstraint']\n",
    "region = bucket_location if bucket_location else 'us-east-1'\n",
    "\n",
    "print(f\"üåç Detected region: {region}\")\n",
    "\n",
    "# Initialize boto3 session with detected region\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n",
    "\n",
    "# Get IAM role ARN\n",
    "iam_client = boto_session.client('iam')\n",
    "role_response = iam_client.get_role(RoleName=ROLE_NAME)\n",
    "TRAIN_ROLE_ARN = role_response['Role']['Arn']\n",
    "\n",
    "print(f\"‚úì SageMaker session initialized\")\n",
    "print(f\"‚úì Region: {region}\")\n",
    "print(f\"‚úì Role ARN: {TRAIN_ROLE_ARN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab1efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emergency: Stop all in-progress training jobs\n",
    "import boto3\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker', region_name='us-east-1')\n",
    "\n",
    "print(\"üîç Looking for in-progress training jobs...\")\n",
    "response = sagemaker_client.list_training_jobs(\n",
    "    StatusEquals='InProgress',\n",
    "    MaxResults=10\n",
    ")\n",
    "\n",
    "if response['TrainingJobSummaries']:\n",
    "    print(f\"\\n‚ö†Ô∏è  Found {len(response['TrainingJobSummaries'])} in-progress job(s):\\n\")\n",
    "    \n",
    "    for job in response['TrainingJobSummaries']:\n",
    "        job_name = job['TrainingJobName']\n",
    "        status = job['TrainingJobStatus']\n",
    "        created = job['CreationTime']\n",
    "        \n",
    "        print(f\"üì¶ Job: {job_name}\")\n",
    "        print(f\"   Status: {status}\")\n",
    "        print(f\"   Created: {created}\")\n",
    "        \n",
    "        # Stop the job\n",
    "        print(f\"   üõë Stopping job...\")\n",
    "        try:\n",
    "            sagemaker_client.stop_training_job(TrainingJobName=job_name)\n",
    "            print(f\"   ‚úÖ Stop command sent successfully!\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error: {e}\\n\")\n",
    "    \n",
    "    print(\"‚è≥ Jobs are stopping... wait 1-2 minutes before starting new training.\")\n",
    "else:\n",
    "    print(\"‚úÖ No in-progress training jobs found!\")\n",
    "    print(\"   You're clear to start training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c53fb3d",
   "metadata": {},
   "source": [
    "## ALTERNATIVE: Use Existing Trained Model (If Available)\n",
    "\n",
    "‚ö° **Skip Training**: If you already have a trained model in S3, deploy it directly!\n",
    "\n",
    "This will check for existing model artifacts and deploy them without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb783a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import boto3\n",
    "\n",
    "print(\"\udd0d Checking for existing trained models in S3...\\n\")\n",
    "\n",
    "# Check for existing model artifacts\n",
    "s3_client = boto3.client('s3')\n",
    "bucket = MODEL_OUTPUT_S3.split('/')[2]\n",
    "prefix = '/'.join(MODEL_OUTPUT_S3.split('/')[3:])\n",
    "\n",
    "try:\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix, MaxKeys=10)\n",
    "    \n",
    "    if 'Contents' in response:\n",
    "        # Find model.tar.gz files\n",
    "        model_files = [obj['Key'] for obj in response['Contents'] \n",
    "                      if obj['Key'].endswith('model.tar.gz')]\n",
    "        \n",
    "        if model_files:\n",
    "            # Use the most recent model\n",
    "            latest_model = sorted(model_files)[-1]\n",
    "            model_data_s3 = f\"s3://{bucket}/{latest_model}\"\n",
    "            \n",
    "            print(f\"‚úÖ Found existing model!\")\n",
    "            print(f\"üì¶ Model: {model_data_s3}\\n\")\n",
    "            \n",
    "            # Create model with your custom inference code\n",
    "            huggingface_model = HuggingFaceModel(\n",
    "                model_data=model_data_s3,\n",
    "                role=TRAIN_ROLE_ARN,\n",
    "                entry_point='inference.py',\n",
    "                source_dir='../training',\n",
    "                transformers_version=TRANSFORMERS_VERSION,\n",
    "                pytorch_version=PYTORCH_VERSION,\n",
    "                py_version=PYTHON_VERSION,\n",
    "            )\n",
    "            \n",
    "            # Generate endpoint name\n",
    "            timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "            endpoint_name = f'acousticshield-existing-{timestamp}'\n",
    "            \n",
    "            print(f\"üåê Endpoint: {endpoint_name}\")\n",
    "            print(f\"üíª Instance: {ENDPOINT_INSTANCE_TYPE}\")\n",
    "            print(f\"\\n‚è∞ Deploying existing model... (5-8 minutes)\\n\")\n",
    "            \n",
    "            # Deploy endpoint\n",
    "            predictor = huggingface_model.deploy(\n",
    "                initial_instance_count=ENDPOINT_INSTANCE_COUNT,\n",
    "                instance_type=ENDPOINT_INSTANCE_TYPE,\n",
    "                endpoint_name=endpoint_name,\n",
    "                serializer=DataSerializer(content_type='audio/wav'),\n",
    "                deserializer=JSONDeserializer(),\n",
    "            )\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"‚úÖ EXISTING MODEL DEPLOYED!\")\n",
    "            print(\"=\"*80)\n",
    "            print(f\"üåê Endpoint: {endpoint_name}\")\n",
    "            print(f\"‚úÖ Status: InService\")\n",
    "            print(f\"\udce6 Model: {model_data_s3}\")\n",
    "            print(f\"\\nüí° Next: Run Step 6 (Test Endpoint) to try it out!\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  No trained models found in S3!\")\n",
    "            print(f\"   Location checked: {MODEL_OUTPUT_S3}\")\n",
    "            print(f\"\\nüí° You need to train a model first:\")\n",
    "            print(f\"   1. Stop any running training jobs (Emergency cell)\")\n",
    "            print(f\"   2. Run Step 3 (Create estimator)\")\n",
    "            print(f\"   3. Run Step 4 (Start training)\")\n",
    "            print(f\"   4. Wait 15-20 minutes for training to complete\")\n",
    "            print(f\"   5. Then come back here to deploy!\")\n",
    "            \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No objects found in model output bucket!\")\n",
    "        print(f\"   Location: {MODEL_OUTPUT_S3}\")\n",
    "        print(f\"\\nüí° Train a model first using Steps 3-4\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error checking S3: {e}\")\n",
    "    print(f\"\\nüí° Options:\")\n",
    "    print(f\"   1. Train a new model (Steps 3-4)\")\n",
    "    print(f\"   2. Check AWS credentials\")\n",
    "    print(f\"   3. Verify S3 bucket permissions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba3b4e",
   "metadata": {},
   "source": [
    "## Step 3: Create HuggingFace Estimator\n",
    "\n",
    "Configure the training job with the HuggingFace estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec927d59",
   "metadata": {},
   "source": [
    "## Step 2.5: Split Train/Validation Data (Optional)\n",
    "\n",
    "If you don't have a separate validation set, run this cell to split your training data (80/20 split).\n",
    "\n",
    "‚ö†Ô∏è **Run this only once** - it will reorganize your S3 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d067c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Configuration\n",
    "SPLIT_RATIO = 0.8  # 80% train, 20% validation\n",
    "SOURCE_PREFIX = 'train/'\n",
    "TRAIN_PREFIX = 'train_split/'\n",
    "VAL_PREFIX = 'val/'\n",
    "CLASSES = ['CollisionImminent', 'EmergencyBraking', 'Normal', 'TireSkid']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üîÄ Splitting Training Data into Train/Val Sets\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Split ratio: {SPLIT_RATIO*100:.0f}% train, {(1-SPLIT_RATIO)*100:.0f}% validation\")\n",
    "print(f\"Source: s3://{bucket_name}/{SOURCE_PREFIX}\")\n",
    "print(f\"Train output: s3://{bucket_name}/{TRAIN_PREFIX}\")\n",
    "print(f\"Val output: s3://{bucket_name}/{VAL_PREFIX}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Initialize counters\n",
    "total_files = 0\n",
    "train_count = 0\n",
    "val_count = 0\n",
    "\n",
    "# Process each class\n",
    "for class_name in CLASSES:\n",
    "    print(f\"\\nüìÅ Processing class: {class_name}\")\n",
    "    \n",
    "    # List all files in this class (with pagination for >1000 files)\n",
    "    class_prefix = f\"{SOURCE_PREFIX}{class_name}/\"\n",
    "    files = []\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    \n",
    "    for page in paginator.paginate(Bucket=bucket_name, Prefix=class_prefix):\n",
    "        if 'Contents' in page:\n",
    "            # Get all WAV files from this page\n",
    "            files.extend([obj['Key'] for obj in page['Contents'] if obj['Key'].endswith('.wav')])\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"  ‚ö†Ô∏è  No WAV files found in {class_prefix}\")\n",
    "        continue\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"  ‚ö†Ô∏è  No WAV files found in {class_prefix}\")\n",
    "        continue\n",
    "    \n",
    "    # Shuffle files for random split\n",
    "    random.shuffle(files)\n",
    "    \n",
    "    # Calculate split point\n",
    "    split_idx = int(len(files) * SPLIT_RATIO)\n",
    "    train_files = files[:split_idx]\n",
    "    val_files = files[split_idx:]\n",
    "    \n",
    "    print(f\"  Total files: {len(files)}\")\n",
    "    print(f\"  Train: {len(train_files)}, Val: {len(val_files)}\")\n",
    "    \n",
    "    # Copy train files\n",
    "    for file_key in train_files:\n",
    "        filename = file_key.split('/')[-1]\n",
    "        new_key = f\"{TRAIN_PREFIX}{class_name}/{filename}\"\n",
    "        s3.copy_object(\n",
    "            CopySource={'Bucket': bucket_name, 'Key': file_key},\n",
    "            Bucket=bucket_name,\n",
    "            Key=new_key\n",
    "        )\n",
    "        train_count += 1\n",
    "    \n",
    "    # Copy validation files\n",
    "    for file_key in val_files:\n",
    "        filename = file_key.split('/')[-1]\n",
    "        new_key = f\"{VAL_PREFIX}{class_name}/{filename}\"\n",
    "        s3.copy_object(\n",
    "            CopySource={'Bucket': bucket_name, 'Key': file_key},\n",
    "            Bucket=bucket_name,\n",
    "            Key=new_key\n",
    "        )\n",
    "        val_count += 1\n",
    "    \n",
    "    total_files += len(files)\n",
    "    print(f\"  ‚úì Copied to train_split/ and val/\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Data Split Complete!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total files processed: {total_files}\")\n",
    "print(f\"Train files: {train_count} ({train_count/total_files*100:.1f}%)\")\n",
    "print(f\"Validation files: {val_count} ({val_count/total_files*100:.1f}%)\")\n",
    "print(\"\\nüìç New S3 Structure:\")\n",
    "print(f\"  Train: s3://{bucket_name}/{TRAIN_PREFIX}\")\n",
    "print(f\"  Val: s3://{bucket_name}/{VAL_PREFIX}\")\n",
    "print(\"\\n‚ö†Ô∏è  IMPORTANT: Update configuration cell:\")\n",
    "print(f'  TRAIN_S3 = \"s3://{bucket_name}/{TRAIN_PREFIX}\"')\n",
    "print(f'  VAL_S3 = \"s3://{bucket_name}/{VAL_PREFIX}\"')\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101fee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HuggingFace estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point='train.py',\n",
    "    source_dir='../training',\n",
    "    role=TRAIN_ROLE_ARN,\n",
    "    instance_type=TRAIN_INSTANCE_TYPE,\n",
    "    instance_count=TRAIN_INSTANCE_COUNT,\n",
    "    transformers_version=TRANSFORMERS_VERSION,\n",
    "    pytorch_version=PYTORCH_VERSION,\n",
    "    py_version=PYTHON_VERSION,\n",
    "    hyperparameters={\n",
    "        'epochs': EPOCHS,\n",
    "        'learning-rate': LEARNING_RATE,\n",
    "        'batch-size': BATCH_SIZE,\n",
    "        'warmup-steps': WARMUP_STEPS,\n",
    "        'gradient-accumulation-steps': GRADIENT_ACCUMULATION,\n",
    "    },\n",
    "    output_path=MODEL_OUTPUT_S3,\n",
    "    base_job_name='acousticshield-train',\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    disable_profiler=True,  # Disable profiler to reduce overhead\n",
    "    debugger_hook_config=False,  # Disable debugger to reduce overhead\n",
    ")\n",
    "\n",
    "print(\"‚úì HuggingFace estimator created\")\n",
    "print(f\"  Base job name: acousticshield-train\")\n",
    "print(f\"  Output path: {MODEL_OUTPUT_S3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a64434",
   "metadata": {},
   "source": [
    "## Step 4: Start Training Job\n",
    "\n",
    "‚è±Ô∏è **Expected duration**: 30-40 minutes on ml.g4dn.xlarge\n",
    "\n",
    "The training job will:\n",
    "1. Load audio data from S3 using audiofolder format\n",
    "2. Resample all audio to 16 kHz\n",
    "3. Extract features using wav2vec2 feature extractor\n",
    "4. Fine-tune the model for 4 epochs\n",
    "5. Evaluate on validation set each epoch\n",
    "6. Save best model based on F1 score\n",
    "7. Upload model artifacts to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a76b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training channels\n",
    "training_channels = {'train': TRAIN_S3}\n",
    "\n",
    "# Add validation channel if provided\n",
    "if VAL_S3:\n",
    "    training_channels['validation'] = VAL_S3\n",
    "    print(f\"üìä Using separate validation set: {VAL_S3}\")\n",
    "else:\n",
    "    print(f\"üìä Validation set will be split from training data (90/10)\")\n",
    "\n",
    "print(f\"\\nüöÄ Starting training job...\")\n",
    "print(f\"‚è∞ Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Start training\n",
    "huggingface_estimator.fit(training_channels, wait=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Training job completed!\")\n",
    "print(f\"‚è∞ Finished at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üì¶ Model artifacts: {huggingface_estimator.model_data}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaa537b",
   "metadata": {},
   "source": [
    "## Step 5: Deploy Real-Time Endpoint\n",
    "\n",
    "‚è±Ô∏è **Expected duration**: 5-8 minutes\n",
    "\n",
    "The endpoint will:\n",
    "- Accept audio/wav input (any sample rate, mono or stereo)\n",
    "- Auto-resample to 16 kHz if needed\n",
    "- Return JSON with label, confidence, and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique endpoint name\n",
    "timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "endpoint_name = f'acousticshield-endpoint-{timestamp}'\n",
    "\n",
    "print(f\"üöÄ Deploying endpoint: {endpoint_name}\")\n",
    "print(f\"‚è∞ Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üíª Instance: {ENDPOINT_INSTANCE_TYPE}\")\n",
    "print(\"\\nThis will take 5-8 minutes...\\n\")\n",
    "\n",
    "# Deploy endpoint\n",
    "predictor = huggingface_estimator.deploy(\n",
    "    initial_instance_count=ENDPOINT_INSTANCE_COUNT,\n",
    "    instance_type=ENDPOINT_INSTANCE_TYPE,\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=DataSerializer(content_type='audio/wav'),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Endpoint deployed successfully!\")\n",
    "print(f\"‚è∞ Finished at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üåê Endpoint name: {endpoint_name}\")\n",
    "print(f\"üìç Status: InService\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f15feb",
   "metadata": {},
   "source": [
    "## Step 6: Test Endpoint\n",
    "\n",
    "### Option A: Test with Sample Audio from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421fc41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample audio from S3 for testing\n",
    "import io\n",
    "\n",
    "# List available test files\n",
    "test_bucket = 'acousticshield-ml'\n",
    "test_prefix = 'train/'  # Or 'val/' if validation set exists\n",
    "\n",
    "s3 = boto3.client('s3', region_name=region)\n",
    "response = s3.list_objects_v2(Bucket=test_bucket, Prefix=test_prefix, MaxKeys=10)\n",
    "\n",
    "if 'Contents' in response:\n",
    "    # Find first WAV file\n",
    "    test_files = [obj['Key'] for obj in response['Contents'] if obj['Key'].endswith('.wav')]\n",
    "    \n",
    "    if test_files:\n",
    "        test_file_key = test_files[0]\n",
    "        print(f\"üìÅ Using test file: s3://{test_bucket}/{test_file_key}\")\n",
    "        \n",
    "        # Download file\n",
    "        wav_buffer = io.BytesIO()\n",
    "        s3.download_fileobj(test_bucket, test_file_key, wav_buffer)\n",
    "        wav_bytes = wav_buffer.getvalue()\n",
    "        \n",
    "        print(f\"‚úì Downloaded {len(wav_bytes)} bytes\")\n",
    "    else:\n",
    "        print(\"‚ùå No WAV files found in S3 bucket\")\n",
    "        wav_bytes = None\n",
    "else:\n",
    "    print(f\"‚ùå No objects found at s3://{test_bucket}/{test_prefix}\")\n",
    "    wav_bytes = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c778e08c",
   "metadata": {},
   "source": [
    "### Option B: Generate Synthetic Test Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7697f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic test audio (1 second sine wave at 440 Hz)\n",
    "import numpy as np\n",
    "import wave\n",
    "import struct\n",
    "\n",
    "print(\"üéµ Generating synthetic test audio...\")\n",
    "\n",
    "sample_rate = 16000\n",
    "duration = 1.0\n",
    "frequency = 440.0  # A4 note\n",
    "\n",
    "# Generate sine wave\n",
    "t = np.linspace(0, duration, int(sample_rate * duration))\n",
    "test_audio = 0.3 * np.sin(2 * np.pi * frequency * t)\n",
    "\n",
    "# Convert to 16-bit PCM WAV bytes (no soundfile needed!)\n",
    "wav_buffer = io.BytesIO()\n",
    "\n",
    "# Write WAV header manually\n",
    "with wave.open(wav_buffer, 'wb') as wav_file:\n",
    "    wav_file.setnchannels(1)  # Mono\n",
    "    wav_file.setsampwidth(2)  # 16-bit\n",
    "    wav_file.setframerate(sample_rate)\n",
    "    \n",
    "    # Convert float audio to 16-bit integers\n",
    "    audio_int16 = (test_audio * 32767).astype(np.int16)\n",
    "    \n",
    "    # Write audio data\n",
    "    for sample in audio_int16:\n",
    "        wav_file.writeframes(struct.pack('<h', sample))\n",
    "\n",
    "wav_bytes = wav_buffer.getvalue()\n",
    "\n",
    "print(f\"‚úÖ Generated {len(wav_bytes)} bytes of test audio\")\n",
    "print(f\"   Format: 16 kHz mono WAV, {duration} second sine wave @ {frequency} Hz\")\n",
    "print(f\"\\nüí° Note: This is just test audio to verify endpoint works\")\n",
    "print(f\"   (Not real vehicle sound - just a tone)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d81243e",
   "metadata": {},
   "source": [
    "### Invoke Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6815a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if wav_bytes:\n",
    "    print(\"\\nüîÆ Testing endpoint with format conversion...\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"‚ö†Ô∏è  Note: Pre-trained model needs JSON format, not audio/wav\")\n",
    "    print(\"   Converting audio to JSON array...\\n\")\n",
    "    \n",
    "    try:\n",
    "        import librosa\n",
    "        import numpy as np\n",
    "        \n",
    "        # Load and preprocess audio\n",
    "        print(\"üìä Step 1: Loading audio...\")\n",
    "        audio, sr = librosa.load(io.BytesIO(wav_bytes), sr=16000, mono=True)\n",
    "        print(f\"   ‚úÖ Loaded: {len(audio)} samples at {sr} Hz\")\n",
    "        \n",
    "        # Convert to list for JSON\n",
    "        audio_list = audio.tolist()\n",
    "        print(f\"   ‚úÖ Converted to JSON format\")\n",
    "        \n",
    "        # Try different payload formats\n",
    "        print(\"\\nüìä Step 2: Testing endpoint...\")\n",
    "        \n",
    "        runtime = boto3.client('sagemaker-runtime', region_name=region)\n",
    "        \n",
    "        # Try Method 1: Simple inputs\n",
    "        try:\n",
    "            print(\"   üîÑ Trying format 1: {\\\"inputs\\\": [audio]}...\")\n",
    "            payload = {\"inputs\": audio_list}\n",
    "            \n",
    "            response = runtime.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                ContentType='application/json',\n",
    "                Accept='application/json',\n",
    "                Body=json.dumps(payload)\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response['Body'].read())\n",
    "            \n",
    "            print(\"   ‚úÖ SUCCESS!\\n\")\n",
    "            print(\"=\"*80)\n",
    "            print(\"üìä PREDICTION RESULTS\")\n",
    "            print(\"=\"*80)\n",
    "            print(json.dumps(result, indent=2))\n",
    "            \n",
    "            # Parse and display nicely\n",
    "            if isinstance(result, list) and len(result) > 0:\n",
    "                predictions = result[0] if isinstance(result[0], list) else result\n",
    "                \n",
    "                print(\"\\n\" + \"=\"*80)\n",
    "                print(\"üè∑Ô∏è  TOP PREDICTIONS\")\n",
    "                print(\"=\"*80)\n",
    "                \n",
    "                if isinstance(predictions, list):\n",
    "                    for i, pred in enumerate(predictions[:5], 1):  # Top 5\n",
    "                        if isinstance(pred, dict):\n",
    "                            label = pred.get('label', pred.get('class', 'unknown'))\n",
    "                            score = pred.get('score', pred.get('confidence', 0))\n",
    "                            bar = '‚ñà' * int(score * 50)\n",
    "                            print(f\"{i}. {label:30s} {score:.2%} {bar}\")\n",
    "                \n",
    "                print(\"=\"*80)\n",
    "            \n",
    "            print(\"\\n‚úÖ Endpoint test successful!\")\n",
    "            print(\"üí° The model is working, but predictions are generic\")\n",
    "            print(\"   (not trained on your vehicle sound data)\")\n",
    "            \n",
    "        except Exception as e1:\n",
    "            print(f\"   ‚ùå Format 1 failed: {str(e1)[:100]}\")\n",
    "            \n",
    "            # Try Method 2: With parameters\n",
    "            try:\n",
    "                print(\"   üîÑ Trying format 2: with sampling_rate...\")\n",
    "                payload = {\n",
    "                    \"inputs\": audio_list,\n",
    "                    \"parameters\": {\"sampling_rate\": 16000}\n",
    "                }\n",
    "                \n",
    "                response = runtime.invoke_endpoint(\n",
    "                    EndpointName=endpoint_name,\n",
    "                    ContentType='application/json',\n",
    "                    Accept='application/json',\n",
    "                    Body=json.dumps(payload)\n",
    "                )\n",
    "                \n",
    "                result = json.loads(response['Body'].read())\n",
    "                print(\"   ‚úÖ SUCCESS!\\n\")\n",
    "                print(\"üìä Prediction Results:\")\n",
    "                print(json.dumps(result, indent=2))\n",
    "                print(\"\\n‚úÖ Endpoint test successful!\")\n",
    "                \n",
    "            except Exception as e2:\n",
    "                print(f\"   ‚ùå Format 2 failed: {str(e2)[:100]}\")\n",
    "                print(\"\\n\" + \"=\"*80)\n",
    "                print(\"‚ùå ENDPOINT FORMAT INCOMPATIBLE\")\n",
    "                print(\"=\"*80)\n",
    "                print(\"\\nüéØ BOTTOM LINE:\")\n",
    "                print(\"   The pre-trained model doesn't work well for audio classification.\")\n",
    "                print(\"\\nüí° YOUR BEST OPTION (30 min to working demo):\")\n",
    "                print(\"   1. Delete this endpoint (Optional cleanup cell)\")\n",
    "                print(\"   2. Stop old training jobs (Emergency stop cell)\")\n",
    "                print(\"   3. Train your custom model (Steps 3-4, ~20 min)\")\n",
    "                print(\"   4. Deploy with your inference.py\")\n",
    "                print(\"   5. Test with audio/wav - WORKS PERFECTLY!\")\n",
    "                print(\"\\n‚úÖ Benefits of training:\")\n",
    "                print(\"   ‚Ä¢ Accepts audio/wav directly (no conversion)\")\n",
    "                print(\"   ‚Ä¢ Trained on YOUR vehicle sounds\")\n",
    "                print(\"   ‚Ä¢ Recognizes YOUR classes (TireSkid, CollisionImminent, etc.)\")\n",
    "                print(\"   ‚Ä¢ Impresses hackathon judges with real ML\")\n",
    "                print(\"=\"*80)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Audio processing failed: {e}\")\n",
    "        print(f\"\\nüí° Install librosa: pip install librosa\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No test audio available.\")\n",
    "    print(\"üí° Run 'Option B: Generate Synthetic Test Audio' cell first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7decb74e",
   "metadata": {},
   "source": [
    "## Step 7: Test with boto3 SageMaker Runtime (Alternative Method)\n",
    "\n",
    "This demonstrates how to invoke the endpoint using raw boto3 client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca69199",
   "metadata": {},
   "outputs": [],
   "source": [
    "if wav_bytes:\n",
    "    print(\"üîß Testing with boto3 SageMaker Runtime client...\\n\")\n",
    "    \n",
    "    # Create SageMaker Runtime client\n",
    "    runtime_client = boto_session.client('sagemaker-runtime')\n",
    "    \n",
    "    # Invoke endpoint\n",
    "    response = runtime_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='audio/wav',\n",
    "        Accept='application/json',\n",
    "        Body=wav_bytes\n",
    "    )\n",
    "    \n",
    "    # Parse response\n",
    "    result = json.loads(response['Body'].read().decode())\n",
    "    \n",
    "    print(\"üìä Response from boto3 client:\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "    print(f\"\\n‚úÖ boto3 invocation successful!\")\n",
    "    print(f\"   Predicted: {result['label']} ({result['confidence']:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323892e1",
   "metadata": {},
   "source": [
    "## Step 8: Endpoint Information\n",
    "\n",
    "Save endpoint details for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ba70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã ENDPOINT INFORMATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Endpoint Name: {endpoint_name}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Instance Type: {ENDPOINT_INSTANCE_TYPE}\")\n",
    "print(f\"Instance Count: {ENDPOINT_INSTANCE_COUNT}\")\n",
    "print(f\"Model Artifacts: {huggingface_estimator.model_data}\")\n",
    "print(f\"\\nInput Format: audio/wav (16 kHz mono recommended, auto-resampled)\")\n",
    "print(f\"Output Format: application/json\")\n",
    "print(f\"\\nExpected Output:\")\n",
    "print(f\"  {{\")\n",
    "print(f\"    \\\"label\\\": \\\"TireSkid\\\",\")\n",
    "print(f\"    \\\"confidence\\\": 0.85,\")\n",
    "print(f\"    \\\"probs\\\": {{\")\n",
    "print(f\"      \\\"Normal\\\": 0.05,\")\n",
    "print(f\"      \\\"TireSkid\\\": 0.85,\")\n",
    "print(f\"      \\\"EmergencyBraking\\\": 0.08,\")\n",
    "print(f\"      \\\"CollisionImminent\\\": 0.02\")\n",
    "print(f\"    }}\")\n",
    "print(f\"  }}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save endpoint info to file\n",
    "endpoint_info = {\n",
    "    'endpoint_name': endpoint_name,\n",
    "    'region': region,\n",
    "    'instance_type': ENDPOINT_INSTANCE_TYPE,\n",
    "    'model_artifacts': huggingface_estimator.model_data,\n",
    "    'created_at': datetime.now().isoformat(),\n",
    "    'classes': ['Normal', 'TireSkid', 'EmergencyBraking', 'CollisionImminent']\n",
    "}\n",
    "\n",
    "with open('endpoint_info.json', 'w') as f:\n",
    "    json.dump(endpoint_info, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úì Endpoint information saved to endpoint_info.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1353f918",
   "metadata": {},
   "source": [
    "## Optional: Cleanup\n",
    "\n",
    "‚ö†Ô∏è **WARNING**: This will delete the endpoint. You will be charged while the endpoint is running.\n",
    "\n",
    "Uncomment and run the cell below to delete the endpoint when done testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87380ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete endpoint - uncomment the lines below to clean up\n",
    "print(f\"üóëÔ∏è  Deleting endpoint: {endpoint_name}\")\n",
    "print(f\"‚è∞ This takes 1-2 minutes...\\n\")\n",
    "\n",
    "try:\n",
    "    predictor.delete_endpoint()\n",
    "    print(\"‚úÖ Endpoint deleted successfully!\")\n",
    "    print(f\"   Endpoint {endpoint_name} is now removed\")\n",
    "    print(f\"\\nüí∞ Cost savings: No more hourly charges!\")\n",
    "    print(f\"\\n‚ö†Ô∏è  Model artifacts remain in S3 and can be redeployed anytime.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error deleting endpoint: {e}\")\n",
    "    print(f\"\\nüí° Alternative: Delete via AWS Console:\")\n",
    "    print(f\"   1. Go to SageMaker ‚Üí Inference ‚Üí Endpoints\")\n",
    "    print(f\"   2. Find: {endpoint_name}\")\n",
    "    print(f\"   3. Click Actions ‚Üí Delete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eebd7c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "‚úÖ **Training Complete**: Model fine-tuned on audio classification task  \n",
    "‚úÖ **Endpoint Deployed**: Real-time inference endpoint is running  \n",
    "‚úÖ **Testing Complete**: Endpoint responds with predictions  \n",
    "\n",
    "### Next Steps\n",
    "1. Integrate endpoint into your application\n",
    "2. Monitor endpoint metrics in CloudWatch\n",
    "3. Set up auto-scaling if needed\n",
    "4. Retrain periodically with new data\n",
    "\n",
    "### Cost Management\n",
    "- **Training**: One-time cost (~$0.50-1.00)\n",
    "- **Endpoint**: Ongoing cost (~$0.23/hour for ml.m5.xlarge)\n",
    "- **Storage**: Model artifacts in S3 (~$0.02/month)\n",
    "\n",
    "üí° **Tip**: Delete the endpoint when not in use and redeploy when needed to save costs!\n",
    "\n",
    "### Documentation\n",
    "- Endpoint name saved in `endpoint_info.json`\n",
    "- Model artifacts: `s3://acousticshield-ml/models/`\n",
    "- Training logs: Available in CloudWatch"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
